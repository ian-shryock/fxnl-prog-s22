---
title             : "EDLD 653 Final Project"
shorttitle        : "The Personality Structures of the 50 States"

author: 
  - name          : "Anisha Babu, Ian Shryock, Dillon Welindt, Futing Zou, Diana DeWald"
    affiliation   : "1"
    corresponding : yes    
    address       : "1585 E 13th Ave. Eugene, OR 97403"
 

affiliation:
  - id            : "1"
    institution   : "University of Oregon"


authornote: |
 Website for project can be found at: https://github.com/ian-shryock/fxnl-prog-s22

abstract: |
  Big Five personality data were collected from ~114,000 individuals in the US between April 2006 and August 2010. Participants were randomly assigned to     question blocks of an assessment titled ‘International Personality Item Pool Big Five Factor Markers’, to indicate individuals’ Big Five traits (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism). Additionally, demographic data were collected from participants on an optional basis. Such data included questions about participants’ gender, age, country, state (if applicable), race, and education level. We used this demographic data in tandem with trait data to run descriptive, correlational, and factor analyses, hypothesizing that there would be variation in the number of ideal dimensions across states. We found this to be the case, with personality traits demonstrating best fit in a range of 5 to 8 traits across 50 states.

  
keywords          : "Personality traits, SAPA-Project Dataverse, Functional Programming"
wordcount         : "1283"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library(papaja)
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction


## Big Five 
One of the most widely replicated findings within the field of personality psychology is the Big Five structure of personality. With roots in the 1800’s, personality psychology sought to determine the best way to represent the large number of personality traits in a concise structure. This research initially involved researchers providing participants with large numbers of trait descriptive adjectives and asking them to rate the extent to which those adjectives characterize themselves or someone they knew. Dimension reduction analyses were then used to create a simpler structure from those responses. 

Multiple research groups began converging on the five factor structure as early as the 1960’s, with an increasing consensus by the late 1980’s. Most of the recent work on the big five has been conducted through a combination of confirmatory factor analysis and theory driven selection of survey items based on previous findings about the structure. 




## Geographical Personality
In recent years, there has been increasing focus on regional variation of personality traits within the United States. Work has examined the extent to which regions of the US differ on the Big Five domains and can be said to have distinct and characteristic combinations of trait levels. For example, Rentfrow and colleagues (2013) show that the south and midwest are best characterized as friendly and conventional, whereas the west is relaxed and creative, and the northeast is temperamental and uninhibited. 

A limitation of this work is that it examines the extent to which the five factor structure captures each region and what differences in the levels of each factor are due to regional variation. This research utilizes confirmatory factor analyses that assume that the five factor structure is the ideal level of dimensionality to characterize all regions. 

## Cross-Cultural Studies
Much of the cross-cultural work on personality structure has found some support for the notion that the five factor structure has applicability in a number of cultures. However, these studies typically are conducted from an etic perspective that translate the items used in western samples. 

However, when studies are conducted from an emic perspective – that is, using trait descriptive adjectives from the language of the culture, rather than translations of items used in the big five framework – different structures emerge. A varying number of factors have been found to best fit different cultures, ranging from one to seven in many cases.




## Geographical Factor Structure within US
Within the US, the regional variation in factor structures has not been an extensively studied topic. Because most research operates within a framework that utilizes confirmatory factor analysis, there is little information on the extent to which regions differ in their factor structure. 

In the current study, we use exploratory factor analyses to provide estimates of the optimal factor structures for each of the fifty states. 

# Methods

## Measures
The International Personality Item Pool is an open-source repository of personality trait items that have been researched extensively in the big five tradition. The current study uses ninety nine of one hundred items from the IPIP-100. Participants rated themselves on a number of personality traits from 1- not at all like me to 6- very much like me. 

## Data Collection
Data were obtained from the Harvard [Dataverse](https://dataverse.harvard.edu/dataverse/SAPA-Project) (@DVN/2IBBMG_2021). Data were initially collected using the Synthetic Aperture for Personality Assessment [see @revelle2016web; @condon2014international; @wilt2011dynamic] which utilizes a massively missing completely at random design, wherein each participant only provides responses to a fraction of items. 


## Data analysis

First, we provide descriptive norms for the entire US sample, and then by state. 

Next, we use parallel analysis to determine the optimal number of factors in the whole sample. Our hypothesis is that five factors will provide an optimal fit. 

The main analyses are fifty parallel analyses, one for every state, that estimates the optimal number of personality dimensions for each state. We hypothesize that there will be variation in the number of ideal dimensions across states. 



```{r initial, include=FALSE}
library(needs)
needs(tidyverse, dataverse, kableExtra, psych, arsenal, apaTables, here, rio, GPArotation, qgraph)



# download data from url
Sys.setenv("DATAVERSE_SERVER" = "dataverse.harvard.edu")

SAPA <- get_dataframe_by_name(
  "sapaTempData04apr2006thru18aug2010.tab",
  "10.7910/DVN/H9RQD6")


#RG This didn't work for me: Error in get_dataframe_by_name("sapaTempData04apr2006thru18aug2010.tab",  : could not find function "get_dataframe_by_name"
#AB: I think this fxn is just from the psych library right?

# IPIP keys list
IPIPkeysList <- list(
IPIP100agreeableness = c("-q_140", "-q_146", "q_150", "-q_195", "-q_200", 
                         "q_217", "-q_838", "q_844", "q_1041", "q_1053", 
                         "q_1162", "-q_1163", "q_1206", "q_1364", "q_1385", 
                         "q_1419", "q_1705", "q_1763", "q_1792", "q_1832"),
IPIP100conscientiousness = c("q_76", "q_124", "q_530", "q_619", "-q_626", 
                             "-q_904", "q_931", "q_962", "-q_1254", "-q_1255", 
                             "q_1290", "q_1333", "q_1374", "-q_1397", "q_1422", 
                             "-q_1452", "-q_1483", "q_1507", "-q_1696", 
                             "-q_1949"),
IPIP100extraversion = c("-q_241", "q_254", "q_262", "-q_403", "-q_690", "q_698", 
                        "-q_712", "q_815", "q_819", "-q_901", "-q_1114", 
                        "-q_1180", "q_1205", "q_1410", "-q_1480", "q_1742", 
                        "q_1768", "q_1803", "-q_1913"),
IPIP100intellect = c("q_128", "q_132", "-q_194", "q_240", "-q_316", "q_422", 
                     "q_492", "q_493", "-q_609", "q_1050", "q_1058", "-q_1083", 
                     "-q_1088", "q_1090", "q_1388", "q_1392", "q_1738", 
                     "-q_1861", "q_1893", "-q_1964"),
IPIP100stability = c("-q_108", "q_177", "q_248", "-q_497", "-q_890", 
                     "-q_952", "-q_960", "-q_974", "-q_979", "-q_986", 
                     "-q_995", "-q_1020", "-q_1099", "-q_1479", "-q_1505", 
                     "q_1585", "q_1677", "q_1683", "-q_1775", "-q_1989"),
IPIP50agreeableness = c("q_844", "q_1792", "q_1763", "q_150", "q_1419", 
                        "q_1053", "-q_838", "-q_200", "-q_195", "-q_1163"),
IPIP50conscientiousness = c("-q_1255", "-q_1397", "-q_1483", "-q_1696", "q_124", 
                            "q_1290", "q_1507", "q_76", "q_931", "q_962"),
IPIP50extraversion = c("q_819", "q_698", "q_262", "q_1803", "q_1742", "-q_712", 
                       "-q_690", "-q_241", "-q_1180", "-q_1114"),
IPIP50intellect = c("q_128", "q_240", "q_1893", "q_1738", "q_1090", "q_1058", 
                    "q_1050", "-q_609", "-q_194", "-q_1088"),
IPIP50stability = c("-q_108", "-q_1099", "-q_1479", "-q_1989", "-q_497", 
                    "-q_974", "-q_986", "-q_995", "q_1677", "q_248")

)

```

```{r preprocessing, warning = FALSE}
SAPA <- SAPA %>%
  # filter in US
  filter(country == "USA") %>%
  # filter 50 states
  filter(!state %in% c('District of Columbia', 
                       'Guam', 
                       'Palau',
                       'Puerto Rico', 
                       'Virgin Islands',
                       'Northern Mariana Islands', 
                       'American Samoa', 
                       'Marshall Islands', 
                       NA)) 

# filter out rows with all NA
SAPA <- SAPA[rowSums(is.na(SAPA)) < 99, ]

# in list form select only used Q's
usedQ <- colnames(SAPA[8:106])

IPIPkeys <- map(IPIPkeysList, function(x) {
    x[match(usedQ, x)]
    na.omit(x)
})

# select only IPIP 100
IPIPkeys <- IPIPkeys[1:4]

```

```{r demographics, warning= FALSE, echo = FALSE, include = FALSE}
# tableby package not available
map((SAPA[c(2,3,5,6,7)]), table)

```

```{r individual subject scores, warning= FALSE}
# score items
scores <- psych::scoreItems(keys = IPIPkeys, items = SAPA, min = 1, max = 6, 
                            totals = FALSE, impute = 'none')$scores


```

```{r #3, warning= FALSE, echo = FALSE}
# initial pass at demographic table

# demog_tab <- summary(tableby(~ age + gender + race + education, 
#                             data = SAPA, test = FALSE),  
#                     title = "Full Sample Demographics")


# After help from peer review (tables are added in KableOutput codechunk below):
sample <- function(df,x) {
  df %>%
  group_by({{x}}) %>%
  summarize(group_sample = n()) %>%
  ungroup() %>%
  rename(group = {{x}}) %>%
  mutate(total_sample = sum(group_sample),
         percent_sample = group_sample/total_sample) %>%
  select(group,group_sample, percent_sample)
}

# correlation matrix for 4 traits in scores

# initial pass at correlation matrix; this table failed to show significance values 
# res <- cor(cor_data, use = "complete.obs")

# kable(res)

# final (correlation matrix added in KableOutput codechunk below):

 Agreeableness <- scores[1:81366, 1]
 Conscientiousness <- scores[1:81366, 2]
 Extraversion <- scores[1:81366, 3]
 Intellect <- scores[1:81366, 4]

 cor_data <- data.frame(Agreeableness, Conscientiousness, Extraversion, Intellect)
 
```

```{r #4 average scores by factor, warning = FALSE}
# average scores on included survey questions
average_surveyscores <- SAPA %>%
  summarize_at(vars(q_76:q_1989), mean, na.rm = TRUE)

# average scores on survey questions by state (for final: can group by other variables as well)
average_statescores <- SAPA %>%
  group_by(state) %>%
  summarize_at(vars(q_76:q_1989), mean, na.rm = TRUE)

```

```{r #5 factor structure, warning = FALSE, include = FALSE}
#allFA <- fa.parallel(SAPA[,8:106], use = "pairwise.complete.obs",cor="cor", n.iter = 2)
#allFA$nfact
```

```{r #6/7 state-wise descriptives, warning = FALSE, include = FALSE}
# combine demographics & traits
factorSAPA <- cbind(SAPA[1:7], scores)

# add extra state column
factorSAPAstate <- factorSAPA %>%
  mutate(state_name = state)

# nest data by state
by_state <- split(factorSAPAstate, factorSAPAstate$state)

# descriptive stats - THERE SHOULD BE A BETTER WAY TO DO THIS (SOME KIND OF NESTED MAP FXN?)  ## summarize_at? 
# I am not sure but I feel like map2 could work here if you have a vector of variable names. (Murat comment)
# AB: I am not sure that map2 would actually be more efficient since the variable names are different for each of the 4 factors. So it would have to be done 4 separate times anyway ...?

stateAgree <- map(by_state, ~summarize(.x, meanFactor = mean(IPIP100agreeableness, na.rm = TRUE),
                                    sdFactor = sd(IPIP100agreeableness, na.rm = TRUE),
                                    nFactor = length(IPIP100agreeableness),
                                    stateName = state_name[1],
                                    factorName = "Agreeableness"))

stateCons <- map(by_state, ~summarize(.x, meanFactor = mean(IPIP100conscientiousness, na.rm = TRUE),
                                    sdFactor = sd(IPIP100conscientiousness, na.rm = TRUE),
                                    nFactor = length(IPIP100conscientiousness),
                                    stateName = state_name[1],
                                    factorName = "Conscientiousness"))

stateExtra <- map(by_state, ~summarize(.x, meanFactor = mean(IPIP100extraversion, na.rm = TRUE),
                                    sdFactor = sd(IPIP100extraversion, na.rm = TRUE),
                                    nFactor = length(IPIP100extraversion),
                                    stateName = state_name[1],
                                    factorName = "Extraversion"))

stateIntel <- map(by_state, ~summarize(.x, meanFactor = mean(IPIP100intellect, na.rm = TRUE),
                                    sdFactor = sd(IPIP100intellect, na.rm = TRUE),
                                    nFactor = length(IPIP100intellect),
                                    stateName = state_name[1],
                                    factorName = "Intellect"))
# group all factors in list
allFactor <- list(stateAgree, stateCons, stateExtra, stateIntel)

names(allFactor) = c('Agreeableness', 'Conscientiousness', 'Extraversion', 'Intellect')

# VERSION 1 SEPARATE TABLES FOR ALL FACTOR/STATE COMBINATIONS

# function to create table 
makeTable <- function(x, name=deparse(substitute(x))) {
  kable(x[1:3], booktabs = TRUE, longtable = TRUE, col.names = c("Mean", "SD", "N"), 
        caption = paste('State of ', x[4], ' ', x[5], ' Descriptives')) %>% 
    landscape() %>% 
    kable_styling(font_size = 12, latex_options = c("scale_down", "repeat_header")) %>% 
    kable_classic() 
}

# create tables for each factor & state
map(allFactor, ~map(.x, ~makeTable(.x)))




# VERSION 2 FROM PEER REVIEW:
# They suggested using the gt package, but it does not seem to be available for this version of R

# summarize each factor by state
state_factor_agree <- tibble(
  state_names = names(stateAgree),
  agree_mean = map_df(stateAgree,~.x[1]),
  agree_sd = map_df(stateAgree,~.x[2]),
  agree_n = map_df(stateAgree,~.x[3]),
)


stateAgreeDF <- reduce(stateAgree, rbind)
AgreeZscores <- map2(stateAgreeDF[1], stateAgreeDF[2], ~((stateAgreeDF[1]-mean(stateAgreeDF$meanFactor))/stateAgreeDF[2])) %>% reduce(stateAgree, rbind)


# state_factor_agree <- tibble(
#   state_names = names(stateAgree),
#   agree_mean = map_dbl(stateAgree,~.x[[1]][1]),
#   agree_sd = map_dbl(stateAgree,~.x[[2]][1]),
#   agree_n = map_int(stateAgree,~.x[[3]][1]),
# )

state_factor_cons <- tibble(
  state_names = names(stateCons),
  cons_mean = map_df(stateCons,~.x[1]),
  cons_sd = map_df(stateCons,~.x[2]),
  cons_n = map_df(stateCons,~.x[3]),
)
state_factor_extra <- tibble(
  state_names = names(stateExtra),
  extra_mean = map_df(stateExtra,~.x[1]),
  extra_sd = map_df(stateExtra,~.x[2]),
  extra_n = map_df(stateExtra,~.x[3]),
)
state_factor_intel <- tibble(
  state_names = names(stateIntel),
  intel_mean = map_df(stateIntel,~.x[1]),
  intel_sd = map_df(stateIntel,~.x[2]),
  intel_n = map_df(stateIntel,~.x[3]),
)


kable(state_factor_agree, booktabs = TRUE, longtable = TRUE, col.names = c("State", "Mean", "SD", "N"), 
    caption = "Agreeableness Descriptives") %>% 
    landscape() %>% 
    kable_styling(font_size = 12, latex_options = c("scale_down", "repeat_header")) %>% 
    kable_classic() 
kable(state_factor_cons, booktabs = TRUE, longtable = TRUE, col.names = c("State", "Mean", "SD", "N"), 
    caption = "Conscientiousness Descriptives") %>% 
    landscape() %>% 
    kable_styling(font_size = 12, latex_options = c("scale_down", "repeat_header")) %>% 
    kable_classic() 
kable(state_factor_extra, booktabs = TRUE, longtable = TRUE, col.names = c("State", "Mean", "SD", "N"), 
    caption = "Extraversion Descriptives") %>% 
    landscape() %>% 
    kable_styling(font_size = 12, latex_options = c("scale_down", "repeat_header")) %>% 
    kable_classic() 
kable(state_factor_intel, booktabs = TRUE, longtable = TRUE, col.names = c("State", "Mean", "SD", "N"), 
    caption = "Intellect Descriptives") %>% 
    landscape() %>% 
    kable_styling(font_size = 12, latex_options = c("scale_down", "repeat_header")) %>% 
    kable_classic() 

```

```{r KableOuput, echo = FALSE, message=FALSE, warning=FALSE}

kable(sample(SAPA,race), caption = "Race Demographics", col.names = c("Race", "N", "Prop.  of Sample"))
kable(sample(SAPA,education), caption = "Education Demographics", col.names = c("Education", "N", "Prop.of Sample"))

# apa.cor.table(cor_data, filename="Corr_table.doc", show.sig.stars = TRUE)

kable(state_factor_agree, booktabs = TRUE, longtable = TRUE, col.names = c("State", "Mean", "SD", "N"), 
    caption = "Agreeableness Descriptives") %>% 
    landscape() %>% 
    kable_styling(font_size = 12, latex_options = c("scale_down", "repeat_header")) %>% 
    kable_classic() 
kable(state_factor_cons, booktabs = TRUE, longtable = TRUE, col.names = c("State", "Mean", "SD", "N"), 
    caption = "Conscientiousness Descriptives") %>% 
    landscape() %>% 
    kable_styling(font_size = 12, latex_options = c("scale_down", "repeat_header")) %>% 
    kable_classic() 
kable(state_factor_extra, booktabs = TRUE, longtable = TRUE, col.names = c("State", "Mean", "SD", "N"), 
    caption = "Extraversion Descriptives") %>% 
    landscape() %>% 
    kable_styling(font_size = 12, latex_options = c("scale_down", "repeat_header")) %>% 
    kable_classic() 
kable(state_factor_intel, booktabs = TRUE, longtable = TRUE, col.names = c("State", "Mean", "SD", "N"), 
    caption = "Intellect Descriptives") %>% 
    landscape() %>% 
    kable_styling(font_size = 12, latex_options = c("scale_down", "repeat_header")) %>% 
    kable_classic() 
```


```{r #9 factor structure - from nested states, include = FALSE, warning = FALSE, eval = F}
by_stateFactors <- split(SAPA, factorSAPA$state)

stateFactors <- SAPA %>% group_by(state) %>% nest() %>% 
  mutate(factors = map(data, ~fa.parallel(cov(.x[,7:105], use = "pairwise.complete.obs"), n.iter = 5, cor = "cov")$nfact), kmo = map(data, ~KMO(.x[,7:105])$MSA) )

stateFactor <- stateFactors$factors

# stateFactor <- map(by_stateFactors, ~fa.parallel(cov(.x[,8:106], use = "pairwise.complete.obs"), n.iter = 20, cor = "cov")$nfact)
# stateFactordf <- t(as.data.frame(stateFactor))

getmode <- function(pass) {
   unique <- unique(pass)
   unique[which.max(tabulate(match(pass, unique)))]
}
getmode(purrr::reduce(stateFactor, rbind))
min(purrr::reduce(stateFactor, rbind))
max(purrr::reduce(stateFactor, rbind))
table(purrr::reduce(stateFactor, rbind))
```

```{r #9 table, warning = FALSE, include = FALSE}
load(here("data", "statefactor.rda"))
stateFactordf

```

```{r #10 prep efas, warning = FALSE, echo = FALSE}
## Using a larger dataset for the following analyses (correlation matrices couldn't full be estimated)
load(here("data", "statefactor.rda"))
SAPA2 <- get_dataframe_by_name(
  "sapaTempData373items18aug2010thru08dec2013.tab",
  "10.7910/DVN/C40K1U")
items <- import(here("data", "IPIPitemLists.rdata"))

ip <- items[1:5] %>% unlist() 
names(ip) <- NULL
SAPA2 <- SAPA2 %>% 
    # filter in US
  filter(country == "USA") %>%
  # filter 50 states
  filter(!state %in% 
           c('District of Columbia', 'Guam', 'Palau',
             'Puerto Rico', 'Virgin Islands',
             'Northern Mariana Islands', 'American Samoa', 
             'Marshall Islands', NA)) %>% 
  select(state, all_of(ip))
  


stateFacLong <- stateFactordf %>% 
  pivot_longer(everything(), names_to = "state", values_to = "nfact") %>% 
  mutate(state = gsub(".", " ", state, fixed = TRUE))

nest_stateFactors <- SAPA2 %>% 
  group_by(state) %>% 
  #select(starts_with("q")) %>% 
  nest()

for_efa <- left_join(nest_stateFactors, stateFacLong)
```


```{r #10 run efa, warning = FALSE, echo = FALSE, eval = FALSE}
efaSolutions <- for_efa %>% mutate(solution = list(fa(as.data.frame(data), 
                                                      nfactors = nfact, 
                                                      rotate = "oblimin")$loadings))
save(efaSolutions, file = here("data", "solutions2.rda")) 
```


```{r  warning = FALSE, echo = FALSE, eval = F}
## regrettably, qgraph automatically plots, resulting in all 50 plots rendered
## 
load(here("data", "solutions2.rda"))


efaSolutions2 <- efaSolutions %>% 
  mutate(plot = map(
    solution,
  ~{qgraph(.x,
       minimum = 0.2, cut = 0.4, 
       vsize = c(1, 15),borders = FALSE, 
       asize = 0.07, esize = 4, vTrans = 200)
    }
  )
  )

save(efaSolutions2, file = here("data", "netplots.rda"))
```


```{r  warning = FALSE, echo = FALSE}
## get loadings for whole population
five_factor <- fa(SAPA2 %>% select(starts_with("q")), 
                  nfactors = 5, rotate = "oblimin")
```


# Results
The parallel factor analyses indicate that the modal number of factors is 5, as is found in 36 of the 50 states, with 7, 6, and 1 states respectively being better represented by 6, 7, and 8 factors. This analysis relies on covariance matrices uing pairwise complete observations; use of a raw matrix does not converge for each state. However, where such analyses are convergent, findings indicate a factor structure of approximately 20-30.

```{r  warning = FALSE, echo = FALSE}
load(here("data", "netplots.rda"))
qgraph(five_factor$loadings, minimum = 0.2, cut = 0.4, 
       vsize = c(1, 15),borders = FALSE, 
       asize = 0.07, esize = 4, vTrans = 200)
title("Personality Structure for United States")

qgraph(efaSolutions2$plot[[1]])
title(paste0("Personality Structure for ", efaSolutions2[[1]][1]))

qgraph(efaSolutions2$plot[[25]])
title(paste0("Personality Structure for ", efaSolutions2[[1]][25]))

qgraph(efaSolutions2$plot[[50]])
title(paste0("Personality Structure for ", efaSolutions2[[1]][50]))


```


# Discussion

These findings appear to confirm the Big Five factor structure of personality. However, this conclusion is extremely tentative, and relies on numerous assumptions holding, for which there is little basis. Most notably, the Kaiser, Meyer, Olkin Measure of Sampling Adequacy indicates a "Marvelous" (@kaiser1974index) measure of the whole sample, whereas no state on it's own is acceptable for factor analysis by those same standards. The complete sample appears to have a 20-factor structure which is more consistent with the findings of related SAPA studies, which finds a 27-factor structure. That the complete sample yielded a 20-factor structure in our exploratory analysis, suggests: 1. an issue of completeness limiting state-level inference (an expected outcome of the SAPA sampling strategy), and; 2. A potential hierarchical factor structure in which the 20 factors aggregate to fewer.

However, barring this issue, it appears notable that smaller states are better represented by more than five factors. This is surprising, as there were no a priori data of the populations of these states entered into the analyses, and thus, such inferences are not based on a more robust estimate. Further inspection demonstrates that states with a larger number of factors have a number of responses approximately commensurate with their state population size; that is to say, less populous states produce fewer observations and a higher factor structure. It seems a reasonable hypothesis that these findings are not well-founded.

Thus, while state-level (dis)confirmation of any extant published personality structure, and demonstration of the homogeneity therein remains a fruitful endeavor, these data do not admit to being interpreted to those ends. SAPA, relying on large degrees of missingness, is not well-suited for such a degree of granularity. A shorter, but more complete personality questionnaire would be more apt. However, stable measures of an individual's personality is a function of the number of items, and thus limits the number of factors to extract. Thus, there is a tension between the so-called "Big Few" and personality structures comprised of more numerous factors. Due to the limited attention of any respondent, and limited resources of researchers to incentivize larger questionnaires, the Big Few personality structure will continue to be reified; if factors aggregate to form this structure, this measurement is limited but valid. To the extent that they do not, these prevailing structures are increasingly problematic.

\newpage

We used the following R packages for this manuscript: `r cite_r("r-references.bib")`

\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
